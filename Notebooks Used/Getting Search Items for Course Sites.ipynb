{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fatty-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "mighty-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "###MONSTER DATASET CLEANING\n",
    "monster = pd.read_csv('monster.csv')\n",
    "monster['skills'] = monster['skills'].to_string()\n",
    "cleaning = pd.DataFrame(columns=['lower','num'])\n",
    "\n",
    "cleaning['liststring'] = [','.join(map(str, l)) for l in monster['skills']]\n",
    "cleaning['lower'] = [i.lower() for i in monster['skills']]\n",
    "cleaning['num'] = [re.sub(r'\\w*\\d\\w*', '', i).strip() for i in cleaning['lower']]\n",
    "monster['skills'] = [s.translate(str.maketrans('','',string.punctuation)) for s in cleaning['num']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "european-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "###JOBSTREET DATASET\n",
    "jobstreet = pd.read_csv('jobstreet.csv')\n",
    "jobstreet = jobstreet.rename(columns={'Skills':'skills'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "gross-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.concat([monster, jobstreet], axis=0)\n",
    "initial_df.head(10)\n",
    "initial_df.to_csv('combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedicated-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = pd.read_csv('combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "multiple-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_doc = []\n",
    "for x in initial_df['skills'].iloc[0:]:\n",
    "    skills_doc.append(x)\n",
    "\n",
    "skills_doc = ' '.join([str(elem) for elem in skills_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parental-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stop = [\"data\",'business','candidate', 'experience', 'work', 'analysis','knowledge','tools','working','years','science','must','models','required','script','analytics','support','design','development','management','skills','degree','andor','reports','including','communication',\\\n",
    "       'related','information','requirements','team','performance','learning','ability','process','processes','technology','analyze','sales','risk','related','new','client','project','operations','written','quality','nan','technical','time','computer','field','based','insights',\\\n",
    "       'engineering','complex','strong','high','statistical','provide','financial','understanding','leadership','office','customer','employees','communicate','etc','clients','identify','develop','operational','possess','multiple','able','results','internal','stakeholders','ensure',\\\n",
    "       'systems','groups','bachelorscollege','company', 'partners','approach','model','end','ie','projects','intermediateexpert','relevant','key','benefits','global','familiarity','software','issues','advanced','resource','processing','maintain','datasets','meet','wellness','database',\\\n",
    "       'specific','test','sss','creating','compensation','big','trends','solutions','power','teams','large','quantitative','job','regular','assigned','use','sources','variable','tool','actionable','appropriate','metrics','output','finance','problem','home','system','good','understand',\\\n",
    "       'predictive','execution','campaign', 'planning','organization','bir','attention','documents','analyzing','improve','order','level','source','positions','problems','verbal','graduate','different','solving','requests','available','training','findings','implementation','account',\\\n",
    "       'platforms','help','improvement','implement','generate','ms','equivalentat','delivery','plans','existing','center','opportunities','external','accuracy','effectively','report','technologies','collaboration','accurate','excellent','closely','philhealth','pagibig','id','experienced'\\\n",
    "       'certificate','equivalentfulltime','computertelecommunication','scienceinformation','nurse','handson','payroll','implementations','understoodensure','prepare','takes','commission','ortigas','list','user','validate','profile','share','open','positionpreferably','senior','tin','certificate']\n",
    "\n",
    "for word in stop:\n",
    "    STOP_WORDS.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 55000000\n",
    "\n",
    "doc = nlp(skills_doc, disable = ['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "blocked-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_doc=[]\n",
    "    \n",
    "for token in doc1:\n",
    "    if token.is_stop==False:\n",
    "        clean_doc.append(token.text)\n",
    "\n",
    "doc = \" \".join(clean_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "romance-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = str(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "sacred-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "sublime-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "data = []\n",
    "for col in response.nonzero()[1]:\n",
    "    data.append([feature_names[col], response[0,col]])\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['features', 'values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('values',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "developing-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = df.sort_values('values',ascending=False)\n",
    "skills_df.to_csv('skillsdf.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
