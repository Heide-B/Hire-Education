{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6278b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274bedcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for hour, name, avg_rating, enrollment, difficulty, link, site \n",
    "\n",
    "def coursera_scraper (keyword):\n",
    "    \n",
    "    keyword = re.sub(\" \",\"%20\",keyword)\n",
    "    url = f\"https://www.coursera.org/search?query={keyword}&index=prod_all_products_term_optimization&entityTypeDescription=Courses&allLanguages=English\"\n",
    "    page = list(range(2,30))\n",
    "    urls = []\n",
    "    urls.append(url)\n",
    "    for i in page:\n",
    "        urls.append(\"https://www.coursera.org/search?query=\" + keyword + \"&page=\"+ str(i) + \"&index=prod_all_products_term_optimization&entityTypeDescription=Courses&allLanguages=English\")\n",
    "\n",
    "\n",
    "    hour = []\n",
    "    name = []\n",
    "    avg_rating = []\n",
    "    enrollment = []\n",
    "    difficulty = []\n",
    "    link = []\n",
    "    site = []\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            website_url = requests.get(url, \\\n",
    "                                  headers = {'User-Agent' : 'Mozilla/5.0 (X11; Linux x86_64)'}).text\n",
    "            soup_html = BeautifulSoup(website_url, \"lxml\")\n",
    "            courses = soup_html.findAll(\"script\")\n",
    "            html = courses[4]\n",
    "            json_object = json.loads(html.contents[0])\n",
    "            t =  json_object[\"props\"][\"pageProps\"][\"resultsState\"]\n",
    "            for i in t:\n",
    "                x = i['content'][\"_rawResults\"][0][\"hits\"]\n",
    "                for j in x:\n",
    "                    if(\"avgLearningHours\" in j):\n",
    "                        hour.append(j[\"avgLearningHours\"])\n",
    "                        name.append(j[\"name\"])\n",
    "                        avg_rating.append(j[\"avgProductRating\"])\n",
    "                        enrollment.append(j[\"enrollments\"])\n",
    "                        difficulty.append(j[\"productDifficultyLevel\"])\n",
    "                        link.append('https://www.coursera.org' + j[\"objectUrl\"])\n",
    "                        site.append('cousera')\n",
    "            \n",
    "            time.sleep(random.randint(5,15))\n",
    "            print(url)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "\n",
    "    course_df = pd.DataFrame({'hour': hour, 'name': name, 'avg_rating': avg_rating, 'enrollment': enrollment, \n",
    "                              'difficulty': difficulty, 'link': link, 'site': site})\n",
    "\n",
    "    return course_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eb8d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe for duration and review\n",
    "def duration_reviews (dataframe):  \n",
    "    duration = []\n",
    "    reviews = []\n",
    "    \n",
    "    for url in dataframe['link']:\n",
    "        try:\n",
    "\n",
    "            website_url = requests.get(url, \\\n",
    "                                      headers = {'User-Agent' : 'Mozilla/5.0 (X11; Linux x86_64)'}).text\n",
    "            soup_html = BeautifulSoup(website_url, \"lxml\")\n",
    "            \n",
    "            # duration\n",
    "            text = soup_html.find_all('div', {\"class\":\"_16ni8zai m-b-0\"})\n",
    "            time_frame = text[4].getText()\n",
    "            length = re.findall('[\\d]{1,2} \\S+', time_frame)\n",
    "            duration.append(length)\n",
    "            \n",
    "            # review\n",
    "            revs = soup_html.find_all('p', {\"class\":\"rc-TopReviewsListItem__comment\"})\n",
    "            review = ''\n",
    "            for i in revs:\n",
    "                review += str(i.getText())\n",
    "            reviews.append(review)\n",
    "            \n",
    "            # sleep\n",
    "            time.sleep(random.randint(5,10))\n",
    "            print(url)\n",
    "\n",
    "        except Exception as e:\n",
    "            duration.append('None indicated')\n",
    "            reviews.append('None indicated')\n",
    "            print (e)\n",
    "    \n",
    "    return pd.DataFrame({'duration': duration, 'review': reviews})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec51cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(keyword):\n",
    "    # Input: keyword is string \n",
    "    df = coursera_scraper(keyword)\n",
    "    dur_rev =  duration_reviews(df)\n",
    "    combined_df = pd.concat([df, dur_rev], axis = 1)\n",
    "    combined_df.to_csv('coursera_' + str(keyword) + '.csv')\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad055b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SAMPLE SCRAPING CODE\n",
    "\n",
    "make_csv('Mathematics')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
