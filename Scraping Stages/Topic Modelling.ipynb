{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unnecessary-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "import math\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    '''\n",
    "    This function takes in texts and converts it to unicode format so we can process it\n",
    "    '''\n",
    "    \n",
    "    return str(''.join([i if ord(i) < 128 else ' ' for i in text]))\n",
    "\n",
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])\n",
    "lee_train_file = test_data_dir + os.sep + 'lee_background.cor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(lee_train_file).read()\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the stopwords from our model vocabulary\n",
    "for stopword in stop_words:\n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(clean(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, article = [], []\n",
    "for w in doc:\n",
    "    if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n",
    "        article.append(w.lemma_)\n",
    "    if w.text == '\\n':\n",
    "        texts.append(article)\n",
    "        article = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find and slice bigrams\n",
    "bigram = gensim.models.Phrases(text)\n",
    "texts = [bigram[line]for line in texts] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSI\n",
    "\n",
    "lsimodel = LsiModel(corpus = corpus, num_topics=10, id2word=dictionary)\n",
    "lsimodel.show_topics(num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LDA\n",
    "\n",
    "ldamodel = LdaModel(corpus = corpus, num_topics=10, id2word=dictionary)\n",
    "ldamodel.show_topics(num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "hdpmodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(ldamodel,corpus,dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsitopics = [[word for word, prob in topic] for topicid, topic in lsimodel.show_topics(formatted=False)]\n",
    "hdptopics = [[word for word, prob in topic] for topicid, topic in hdpmodel.show_topics(formatted=False)]\n",
    "ldatopics = [[word for word, prob in topic] for topicid, topic in ldamodel.show_topics(formatted=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_coherence = CoherenceModel(topics=lsitopics[:10],texts=texts,dictionary=dictionary,window_size=10).get_coherence()\n",
    "hdp_coherence = CoherenceModel(topics=hdptopics[:10],texts=texts,dictionary=dictionary,window_size=10).get_coherence()\n",
    "lda_coherence = CoherenceModel(topics=ldatopics[:10],texts=texts,dictionary=dictionary,window_size=10).get_coherence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bar_graph(coherences, indices):\n",
    "    assert len(coherences) == len(indices)\n",
    "    n = len(coherences)\n",
    "    x = np.arange(n)\n",
    "    plt.bar(x, coherences, width=0.2,tick_label=indices, align='center')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Coherence Value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-morgan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "animal-balance",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentimentIntensityAnalyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-657c43ab533d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'SentimentIntensityAnalyzer' is not defined"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "sid.polarity_scores('I am happy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_transformed = [' '.join(i) for i in texts]\n",
    "texts_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(texts_transformed)):\n",
    "    print(texts_transformed[i] + ': ')\n",
    "    scores = sid.polarity_scores(texts_transformed[i])\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-lesson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "TextBlob('I am bored.').sentiment.polarity #subjectivity\n",
    "\n",
    "for i in range(len(texts_transformed)):\n",
    "    print(texts_transformed[i] + ': ')\n",
    "    scores = TextBlob(texts_transformed[i].sentiment.polarity) #subjectivity\n",
    "    print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
